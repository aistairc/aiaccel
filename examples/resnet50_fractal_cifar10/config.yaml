generic:
  workspace: "./work"
  job_command: "bash exe_parallel.sh"
  # python_file: "./user.py"
  # function: "main"
  batch_job_timeout: 180000

resource:
  type: "abci"
  # type: "local"
  # type: "python_local"
  num_workers: 4

ABCI:
  group: "[group]"
  job_script_preamble: "./job_script_preamble.sh"
  job_execution_options: ""

optimize:
  # search_algorithm: "aiaccel.optimizer.NelderMeadOptimizer"
  search_algorithm: "aiaccel.optimizer.RandomOptimizer"
  # search_algorithm: "aiaccel.optimizer.SobolOptimizer"
  # search_algorithm: "aiaccel.optimizer.GridOptimizer"
  # search_algorithm: "aiaccel.optimizer.TpeOptimizer"
  goal: "minimize"
  trial_number: 1
  rand_seed: 42
  # To add a hyperparameter, modify the following "parameters".
  parameters:
    -
      name: "dummy parameter"
      type: "categorical"
      choices: ["dummy"]

job_setting:
  cancel_retry: 3
  cancel_timeout: 60
  expire_retry: 3
  expire_timeout: 60
  finished_retry: 3
  finished_timeout: 60
  job_retry: 2
  job_timeout: 60
  kill_retry: 3
  kill_timeout: 60
  result_retry: 1
  runner_retry: 3
  runner_timeout: 60
  running_retry: 3
  running_timeout: 60
  init_fail_count: 100
  name_length: 6
  random_scheduling: false
  #random_scheduling: true


logger:
  file:
    master: "master.log"
    optimizer: "optimizer.log"
    scheduler: "scheduler.log"
  log_level:
    master: "CRITICAL"
    optimizer: "CRITICAL"
    scheduler: "CRITICAL"
  stream_level:
    master: "DEBUG"
    optimizer: "DEBUG"
    scheduler: "DEBUG"
